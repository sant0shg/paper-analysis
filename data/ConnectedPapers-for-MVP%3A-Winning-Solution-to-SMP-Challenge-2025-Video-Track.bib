@article{4193e2b5483466ad1db6889a2350d5f8a17e3c2e,
title = {MVP: Winning Solution to SMP Challenge 2025 Video Track},
year = {2025},
url = {https://www.semanticscholar.org/paper/4193e2b5483466ad1db6889a2350d5f8a17e3c2e},
abstract = {Social media platforms serve as central hubs for content dissemination, opinion expression, and public engagement across diverse modalities. Accurately predicting the popularity of social media videos enables valuable applications in content recommendation, trend detection, and audience engagement. In this paper, we present Multimodal Video Predictor (MVP), our winning solution to the Video Track of the SMP Challenge 2025. MVP constructs expressive post representations by integrating deep video features extracted from pretrained models with user metadata and contextual information. The framework applies systematic preprocessing techniques, including log-transformations and outlier removal, to improve model robustness. A gradient-boosted regression model is trained to capture complex patterns across modalities. Our approach ranked first in the official evaluation of the Video Track, demonstrating its effectiveness and reliability for multimodal video popularity prediction on social platforms. The source code is available at https://github.com/yllhwa/SMPDVideo.},
author = {Liliang Ye and Yunyao Zhang and Yafeng Wu and Yi-Ping Phoebe Chen and Junqing Yu and Wei Yang and Zikai Song},
journal = {Proceedings of the 33rd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3746027.3763761},
arxivid = {2507.00950},
}

@article{c39c2c3b27114e4a056152f44846caaa8422cb1c,
title = {Higher-Order Vision-Language Fusion for Video Popularity Prediction},
year = {2025},
url = {https://www.semanticscholar.org/paper/c39c2c3b27114e4a056152f44846caaa8422cb1c},
abstract = {Predicting the popularity of social media videos involves estimating user engagement based on rich multimodal information embedded within the posts. Unlike static images, videos incorporate temporally evolving visual signals that, alongside associated metadata such as descriptions, hashtags, timestamps, and user attributes, offer valuable insights into their potential audience reach. Prior approaches typically extract features from different modalities independently and merge them via naïve concatenation, which overlooks the semantic discrepancy and interaction dynamics across modalities. To address these limitations, we propose a feature fusion framework that encodes and aligns video content and associated textual cues into a shared semantic space. By jointly modeling temporally structured visual features with context-aware textual embeddings, our method effectively captures cross-modal correlations that are crucial for discerning content virality patterns. In addition, we incorporate user-centric behavioral profiles and content creation dynamics, enriching the representation with personalized signals that reflect audience-specific preferences. Notably, our method achieves top-tier performance in the 2025 SMP challenge, ranking among the highest-performing entries. This strong empirical result underscores the value of deep semantic alignment across video, text, and user domains in accurately forecasting social media video popularity.},
author = {Kele Xu and Qisheng Xu and Binli Luo and Han Zhou and Zengming Lin and Hui Geng and Xianhan Tan},
journal = {Proceedings of the 33rd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3746027.3763762},
}

@article{7a89125fa1197c6c3ca9f79b6777ecfabf3263ce,
title = {Catboost-based Framework with Additional User Information for Social Media Popularity Prediction},
year = {2019},
url = {https://www.semanticscholar.org/paper/7a89125fa1197c6c3ca9f79b6777ecfabf3263ce},
abstract = {In this paper, a Catboost-based framework is proposed to predict social media popularity. The framework is constituted by two components: feature representation and Catboost training. In the component of feature representation, numerical features are directly used, while categorical features are converted into numerical features by a method of order target statistics in Catboost. Besides, some additional user information is also tracked to enrich the feature space. In the other component, Catboost is adopted as the regression model which is trained by using post-related, user-related and additional user information. Moreover, to make full use of the dataset for model training, a dataset augmentation strategy based on pseudo labels is proposed. This strategy involves in two-stage training. In the first stage, it trains a first-stage model that is used to label the test set as pseudo labeled. In the next stage, a final model is trained based on the new training set that includes original validation set and the pseudo labeled test set. The proposed method achieves the 2nd place in the leader board of the Grand Challenge of Social Media Prediction.},
author = {Peipei Kang and Zehang Lin and Shaohua Teng and Guipeng Zhang and Lingni Guo and Wei Zhang},
journal = {Proceedings of the 27th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3343031.3356060},
}

@article{ff133e51f3f69256ded21dae777d4c338e6faa6f,
title = {HyFea: Winning Solution to Social Media Popularity Prediction for Multimedia Grand Challenge 2020},
year = {2020},
url = {https://www.semanticscholar.org/paper/ff133e51f3f69256ded21dae777d4c338e6faa6f},
abstract = {Social Media Popularity (SMP) prediction focuses on predicting the social impact of a given post from a specific user in social media, which is crucial for online advertising, social recommendation, and demand prediction. In this paper, we present HyFea, our winning solution to the Social Media Prediction (SMP) Challenge for multimedia grand challenge of ACM Multimedia 2020. To address the multi-modality and personality issues of this challenge, HyFea carefully considers multiple feature types and adopts a tree-based ensembling method, i.e., CatBoost, which is shown to perform well in prediction. Specifically, HyFea involves the features related to Image, Category, Space-Time, User Profile, Tag, and Others. We conduct several experiments on the Social Media Prediction Dataset (SMPD), verifying the positive contributions of each type of features.},
author = {Xin Lai and Yihong Zhang and Wei Zhang},
journal = {Proceedings of the 28th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3394171.3416273},
}

@article{2a363593909d4a88904d6deb970fb2650d161681,
title = {Popularity Prediction of Social Media based on Multi-Modal Feature Mining},
year = {2019},
url = {https://www.semanticscholar.org/paper/2a363593909d4a88904d6deb970fb2650d161681},
abstract = {Popularity prediction of social media becomes a more attractive issue in recent years. It consists of multi-type data sources such as image, meta-data, and text information. In order to effectively predict the popularity of a specified post in the social network, fusing multi-feature from heterogeneous data is required. In this paper, a popularity prediction framework for social media based on multi-modal feature mining is presented. First, we discover image semantic features by extracting their image descriptions generated by image captioning. Second, an effective text-based feature engineering is used to construct an effective word-to-vector model. The trained word-to-vector model is used to encode the text information and the semantic image features. Finally, an ensemble regression approach is proposed to aggregate these encoded features and learn the final regressor. Extensive experiments show that the proposed method significantly outperforms other state-of-the-art regression models. We also show that the multi-modal approach could effectively improve the performance in the social media prediction challenge.},
author = {Chih-Chung Hsu and Li-Wei Kang and Chia-Yen Lee and Jun-Yi Lee and Zhong-Xuan Zhang and Shaozhi Wu},
journal = {Proceedings of the 27th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3343031.3356064},
}

@article{022855e6cecd7ec64ca9faa7a3c66e4b21eaee8c,
title = {Curriculum Learning for Wide Multimedia-Based Transformer with Graph Target Detection},
year = {2020},
url = {https://www.semanticscholar.org/paper/022855e6cecd7ec64ca9faa7a3c66e4b21eaee8c},
abstract = {The social media prediction task is aiming at predicting content popularity which includes social multimedia data such as photos, videos, and news. The task can not only help make better decisions for recommendation, but also reveals the public attention from evolutionary social systems. In this paper, we propose a novel approach named curriculum learning for wide multimedia-based transformer with graph target detection(CL-WMTG). The curriculum learning is designed for the transformer to improve the efficiency of model convergence. The mechanism of wide multimedia-based transformer is to make the model capable of learning cross information from text, pictures and other features(e.g. categories, location). Moreover, the graph target detection part can extract different features in the picture by pretrained model and reconstruct the features with a homogeneous graph network. We achieved third place in the SMP Challenge 2020.},
author = {Weilong Chen and Feng Hong and Chenghao Huang and Shaoliang Zhang and Rui Wang and Ruobing Xie and Feng Xia and Leyu Lin and Yanru Zhang and Yan Wang},
journal = {Proceedings of the 28th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3394171.3416275},
}

@article{bdd5159fa1f831f9bbf9928f168bacfd435af1d6,
title = {Dual-Stream Pre-Training Transformer to Enhance Multimodal Learning for Social Media Prediction},
year = {2024},
url = {https://www.semanticscholar.org/paper/bdd5159fa1f831f9bbf9928f168bacfd435af1d6},
abstract = {Social media has emerged as a vital platform for communication, information sharing, and acquisition. Predictive analysis of social media data has wide applications, such as sentiment examination and social network analysis. However, existing work often directly utilizes social media data for training, neglecting the issue of mismatched text and images. This neglect can lead to confusion about the contents, thereby affecting the identification of trending topics and the accuracy of social media predictions. In this paper, an approach named Dual-Stream Pre-training Transformer (DSPT) is introduced to address this gap. In DSPT, we use a Visual-Language Model (VLM) and a Language Model (LM) to separately learn from image and text data, mitigating the impact of text-image mismatches. Moreover, to enhance the understanding of the model to social media data, we conduct incremental pre-training for both models. To achieve better feature interaction, we construct an integrated regression module combining LightGBM and CatBoost, jointly predicting the extracted feature embeddings. This dual-stream multimodal feature extraction method improves the performance of predictive tasks. Experimental results validate the effectiveness of our approach, demonstrating its potential and providing deeper insights into multimodal data mining in social media.},
author = {Wenhao Hu and Weilong Chen and Weimin Yuan and Yan Wang and Shimin Cai and Yanru Zhang},
journal = {Proceedings of the 32nd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3664647.3688998},
}

@article{78740b176f8fa6b9591f3e653f870afa634dd4d9,
title = {Social Media Popularity Prediction: A Multiple Feature Fusion Approach with Deep Neural Networks},
year = {2019},
url = {https://www.semanticscholar.org/paper/78740b176f8fa6b9591f3e653f870afa634dd4d9},
abstract = {Social media popularity prediction (SMPD) aims to predict the popularity of the post shared on online social media platforms. This task is crucial for content providers and consumers in a wide range of real-world applications, including multimedia advertising, recommendation system and trend analysis. In this paper, we propose to fuse features from multiple sources by deep neural networks (DNNs) for popularity prediction. Specifically, high-level image and text features are extracted by the advanced pretrained DNN, and numerical features are captured from the metadata of the posts. All of the features are concatenated and fed into a regressor with multiple dense layers. Experiments have demonstrated the effectiveness of the proposed model on the ACM Multimedia Challenge SMPD2019 dataset. We also verify the importance of each feature via univariate test and ablation study, and provide the insights of feature combination for social media popularity prediction.},
author = {Keyan Ding and Ronggang Wang and Shiqi Wang},
journal = {Proceedings of the 27th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3343031.3356062},
}

@article{a5664832965c1b60300d1d32f5100ffcd71c76a2,
title = {SMPV: Social Media Prediction for Videos},
year = {2025},
url = {https://www.semanticscholar.org/paper/a5664832965c1b60300d1d32f5100ffcd71c76a2},
abstract = {With the explosive growth of video-centric social media platforms, understanding and predicting video popularity has become a crucial problem in both academia and industry. This year, the Social Media Prediction (SMP) Challenge expands its scope by introducing a dedicated video track, shifting the focus from static images to dynamic, multimodal video content. We introduce the Social Media Prediction for Videos (SMPV) task and release a large-scale, multimodal benchmark dataset, SMPD-Video, with more than 6K short-form videos, including vision language metadata, user profiles, and popularity labels. This challenge invites global researchers to develop predictive algorithms that integrate spatial-temporal dynamics, multimodal learning, and user-video interactions to forecast video popularity in real-world social temporal streams. With the participation and contribution of top teams around the world, the challenge has seen continuous performance improvements in recent years, driven by technological advancements. SMP Challenge Homepage: www.smp-challenge.com.},
author = {Bo Wu and Peiye Liu and Qiushi Huang and Zhaoyang Zeng and Jia Wang and Bei Liu and Jiebo Luo and Wen-Huang Cheng},
journal = {Proceedings of the 33rd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3746027.3763757},
}

@article{911e0ffc5331e5b80317e63dede0c95980b998d9,
title = {Higher-Order Vision-Language Alignment for Social Media Prediction},
year = {2024},
url = {https://www.semanticscholar.org/paper/911e0ffc5331e5b80317e63dede0c95980b998d9},
abstract = {The prediction task of social media popularity aims to automatically forecast the future popularity of the posts by leveraging vast amounts of social media data. This data encompasses diverse visual and textual content, including photos, categories, custom tags, temporal information, and geographical data. Existing methods have explored multiple feature types to enhance popularity prediction. Despite their success, visual and textual features-both crucial pieces of information-are often simply concatenated after extraction, ignoring the divergence between these two feature spaces. In this paper, we propose a method to project visual and language information into an aligned semantic representation, thereby uncovering intricate associations between these two modalities. Specifically, we leverage the BLIP-2 model to understand and generate visual description text that encapsulates the content of photos. Semantic embeddings are then extracted from all available visual and textual information. Additionally, we deeply exploit user-related behavior and characteristic information to extract features, uncovering hidden clues for post popularity prediction. Leveraging these improvements, we conduct extensive experiments to demonstrate the effectiveness of our proposed method.},
author = {Mingsheng Tu and Tianjiao Wan and Qisheng Xu and Xinhao Jiang and Kele Xu and Cheng Yang},
journal = {Proceedings of the 32nd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3664647.3688999},
}

@article{e447f138ef757b3877d041ac5080fce2a187b7df,
title = {A Feature Generalization Framework for Social Media Popularity Prediction},
year = {2020},
url = {https://www.semanticscholar.org/paper/e447f138ef757b3877d041ac5080fce2a187b7df},
abstract = {Social media is an indispensable part in modern life and social media popularity prediction can be applied to many aspects of sociality. In this paper, we propose a novel combined framework for social media popularity prediction, which accomplishes feature generalization and temporal modeling based on multi-modal feature extraction. On the one hand, in order to address the generalization problem caused by massive missing data, we train two CatBoost models with different datasets and integrate their outputs with a linear combination. On the other hand, sliding window average is employed to mine potential short-term dependency for each user's post sequence. Extensive experiments show that our proposed framework has superiorities in both feature generalization and temporal modeling. Besides, our approach achieves the 1st place on the leader board of the SMP Challenge in 2020, which proves the effectiveness of our proposed framework.},
author = {Kai Wang and Penghui Wang and Xin Chen and Qiushi Huang and Zhendong Mao and Yongdong Zhang},
journal = {Proceedings of the 28th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3394171.3416294},
}

@article{b1ebbc2224935a5e60fdad3d3b0c99f636e48bd4,
title = {Enhanced CatBoost with Stacking Features for Social Media Prediction},
year = {2023},
url = {https://www.semanticscholar.org/paper/b1ebbc2224935a5e60fdad3d3b0c99f636e48bd4},
abstract = {The Social Media Prediction (SMP) challenge aims to predict the future popularity of online posts by leveraging social media data. Social media data contains multimodal information, such as text, images, time series, etc. Previous methods have proposed many feature extraction and feature construction methods to represent these multimodal information, thereby predicting the popularity of posts. Despite the success of previous methods in extracting features from social media data, these features tend to be predominantly lower-order, posing a challenge in accurately capturing the rich information contained in text and images. In this paper, we propose a more diverse feature mining method and introduce a stacking block module to capture higher-order feature information contained in text and images. "lower-order" refers to the original high-dimensional embedding representation, while "high-order" pertains to the impact on post social popularity captured by tree models from text or image. We conducted massive experiments to evaluate the effectiveness of our proposed method and found that the stacking block module significantly improved performance.},
author = {Shijian Mao and Wu-Dong Xi and Lei Yu and Gaotian Lü and Xingxing Xing and Xingchen Zhou and Wei Wan},
journal = {Proceedings of the 31st ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3581783.3612839},
}

@article{e8d73901c2a6b54a3863f8d48b707c7631195b63,
title = {Multimodal Deep Learning for Social Media Popularity Prediction With Attention Mechanism},
year = {2020},
url = {https://www.semanticscholar.org/paper/e8d73901c2a6b54a3863f8d48b707c7631195b63},
abstract = {Social media popularity estimation refers to predict the post's popularity using multimodal contents. The prediction performance heavily relies on the feature extraction part and fully leveraging multimodal heterogeneous data is of a great challenge in the practical settings. Despite remarkable progress have been made, most of the previous attempts are restrained from the essentially limited property of the employed single modality. Inspired by the recent success of multimodal learning, we propose a novel multimodal deep learning framework for the popularity prediction task, which aims to leverage the complementary knowledge from different modalities. Moreover, an attention mechanism is introduced in our framework, with the goal to assign large weights to specified modalities during the training and inference phases. To empirically investigate the effectiveness and robustness of the proposed approach, we conduct extensive experiments on the 2020 SMP challenge. The obtained results show that the proposed framework outperforms related approaches.},
author = {Kele Xu and Zhimin Lin and Jianqiao Zhao and Peicang Shi and Wei Deng and Huaimin Wang},
journal = {Proceedings of the 28th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3394171.3416274},
}

@article{f78bac1580dc68788df89d96814546cf7f28c41d,
title = {Rethinking Relation between Model Stacking and Recurrent Neural Networks for Social Media Prediction},
year = {2020},
url = {https://www.semanticscholar.org/paper/f78bac1580dc68788df89d96814546cf7f28c41d},
abstract = {Popularity prediction of social posts is one of the most critical issues for social media analysis and understanding. In this paper, we discover a more dominant feature representation of text information, as well as propose a singe ensemble learning model to obtain the popularity scores, for social media prediction challenge. However, most social media prediction techniques focus on predicting the popularity score of social posts based on a single model, such as deep learning-based or ensemble learning-based approaches. However, it is well-known that the model stacking strategy is a more effective way to boost the performance on various regression tasks. In this paper, we also show that the model stacking can be modeled as a simple recurrent neural network problem with comparable performance on predicting popularity scores. Firstly, a single strong baseline is proposed based on the deep neural network with a prediction branch. Then, the partial feature maps of the last layer of our strong baseline are used to establish a new branch with an isolated predictor. It is easy to obtain multi-prediction by repeating the above two steps. These preliminary predicted scores are then formed as the input of the recurrent unit to learn the final predicted scores, called Recurrent Stacking Model (RSM). Our experiments show that the proposed ensemble learning approach outperforms other state-of-the-art methods. Furthermore, the proposed RSM also shows the superiority over our ensemble learning approach, having verified that the model stacking problem can be transformed into the training problem of a recurrent neural network.},
author = {Chih-Chung Hsu and Wen-Hai Tseng and Hao-Ting Yang and Chia-Hsiang Lin and Chao-Yuan Kao},
journal = {Proceedings of the 28th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3394171.3417332},
}

@article{93a0f87fc64c46f24ac164a7fec41ab47cc62ce6,
title = {HyperFusion: Hierarchical Multimodal Ensemble Learning for Social Media Popularity Prediction},
year = {2025},
url = {https://www.semanticscholar.org/paper/93a0f87fc64c46f24ac164a7fec41ab47cc62ce6},
abstract = {Social media popularity prediction plays a crucial role in content optimization, marketing strategies, and user engagement enhancement across digital platforms. However, predicting post popularity remains challenging due to the complex interplay between visual, textual, temporal, and user behavioral factors. This paper presents HyperFusion, a hierarchical multimodal ensemble learning framework for social media popularity prediction. Our approach employs a three-tier fusion architecture that progressively integrates features across abstraction levels: visual representations from CLIP encoders, textual embeddings from transformer models, and temporal-spatial metadata with user characteristics. The framework implements a hierarchical ensemble strategy combining CatBoost, TabNet, and custom multi-layer perceptrons. To address limited labeled data, we propose a two-stage training methodology with pseudo-labeling and iterative refinement. We introduce novel cross-modal similarity measures and hierarchical clustering features that capture inter-modal dependencies. Experimental results demonstrate that HyperFusion achieves competitive performance on the SMP challenge dataset. Our team achieved third place in the SMP Challenge 2025 (Image Track). The source code is available at https://anonymous.4open.science/r/SMPDImage.},
author = {Liliang Ye and Yunyao Zhang and Yafeng Wu and Yi-Ping Phoebe Chen and Junqing Yu and Wei Yang and Zikai Song},
journal = {ArXiv},
volume = {abs/2507.00926},
pages = {null},
doi = {10.48550/arXiv.2507.00926},
arxivid = {2507.00926},
}

@article{2c1ee0c7e8f5fc768a084fdef3460c15cea4aa87,
title = {Gradient Boost Tree Network based on Extensive Feature Analysis for Popularity Prediction of Social Posts},
year = {2023},
url = {https://www.semanticscholar.org/paper/2c1ee0c7e8f5fc768a084fdef3460c15cea4aa87},
abstract = {Social media popularity (SMP) prediction is a complex task, affected by various features such as text, images, and spatial-temporal information. One major challenge in SMP is integrating features from multiple modalities without overemphasizing user-specific details while efficiently capturing relevant user information. This study introduces a robust multi-modality feature mining framework for predicting SMP scores by incorporating additional identity-related features sourced from the official SMP dataset when a user's path alias is accessible. Our preliminary analyses suggest these supplemental features significantly enrich the user-related context, contributing to a substantial improvement in performance and proving that non-identity features are relatively unimportant. This implies that we should focus more on discovering the identity-related features than other meta-data. To further validate our findings, we perform comprehensive experiments investigating the relationship between those identity-related features and scores. Finally, the LightGBM and TabNet are employed within our framework to effectively capture intricate semantic relationships among different modality features and user-specific data. Our experimental results confirm that these identity-related features, especially external ones, significantly improve the prediction performance of SMP tasks.},
author = {Chih-Chung Hsu and Chia-Ming Lee and Xiu-Yu Hou and Chin-Han Tsai},
journal = {Proceedings of the 31st ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3581783.3612843},
}

@article{53f5f027e31408d817b39bace7ae8d8fd1a0bb11,
title = {Exploring visual relationship for social media popularity prediction},
year = {2022},
url = {https://www.semanticscholar.org/paper/53f5f027e31408d817b39bace7ae8d8fd1a0bb11},
abstract = {null},
author = {Anjin Liu and Hongwei Du and Ning Xu and Quan Zhang and Shenyuan Zhang and Yejun Tang and Xuanya Li},
journal = {J. Vis. Commun. Image Represent.},
volume = {90},
pages = {103738},
doi = {10.1016/j.jvcir.2022.103738},
}

@article{277497372790fbea5a6726930469168e9cdb193c,
title = {SMTPD: A New Benchmark for Temporal Prediction of Social Media Popularity},
year = {2025},
url = {https://www.semanticscholar.org/paper/277497372790fbea5a6726930469168e9cdb193c},
abstract = {Social media popularity prediction task aims to predict the popularity of posts on social media platforms, which has a positive driving effect on application scenarios such as content optimization, digital marketing and online advertising. Though many studies have made significant progress, few of them pay much attention to the integration between popularity prediction with temporal alignment. In this paper, with exploring YouTube’s multilingual and multi-modal content, we construct a new social media temporal popularity prediction benchmark, namely SMTPD, and suggest a baseline framework for temporal popularity prediction. Through data analysis and experiments, we verify that temporal alignment and early popularity play crucial roles in social media popularity prediction for not only deepening the understanding of temporal dynamics of popularity in social media but also offering a suggestion about developing more effective prediction models in this field. Code is available at https://github.com/zhuwei321/SMTPD},
author = {Yijie Xu and Bolun Zheng and Wei Zhu and Hangjia Pan and Yuchen Yao and Ning Xu and An-An Liu and Quan Zhang and Chenggang Yan},
journal = {2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
volume = {null},
pages = {18847-18857},
doi = {10.1109/CVPR52734.2025.01756},
arxivid = {2503.04446},
}

@article{69ec6ecef651c16d31579c4dc1bdd0c9495305d8,
title = {Double-Fine-Tuning Multi-Objective Vision-and-Language Transformer for Social Media Popularity Prediction},
year = {2023},
url = {https://www.semanticscholar.org/paper/69ec6ecef651c16d31579c4dc1bdd0c9495305d8},
abstract = {Social media popularity prediction aims to predict future interaction or attractiveness of new posts. However, in most existing works, there is a notable deficiency in the effective treatment of numerical features. Despite their significant potential to provide ample information, these features are often inadequately processed, leading to insufficiency of information acquirement. In this paper, we introduce a method, named Double-Fine-Tuning Multi-Objective Vision-and-Language Transformer (DFT-MOVLT). To supplement the information in vision-and-language pre-training (VLP), we propose compound text, which is concatenated by numerical data and text. Furthermore, during VLP, a transformer is trained using 3 objectives to ensure thorough feature extraction. Finally, for more generalized prediction, we fine-tune 2 models using different training ways and ensemble them. To evaluate the effectiveness of each mechanism adopted in the proposed method, we conduct an array of ablation experiments. Our team achieve the 3rd place in Social Media Prediction (SMP) Challenge 2023.},
author = {Xiaolu Chen and Weilong Chen and Chenghao Huang and Zhongjian Zhang and Lixin Duan and Yanru Zhang},
journal = {Proceedings of the 31st ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3581783.3612845},
}

@article{f45e5ef5c02628e1ca32f909804acdb46a7fb834,
title = {MMF: Winning Solution to Social Media Popularity Prediction Challenge 2024},
year = {2024},
url = {https://www.semanticscholar.org/paper/f45e5ef5c02628e1ca32f909804acdb46a7fb834},
abstract = {The Social Media Prediction (SMP) challenge focuses on predicting the popularity of an online post in social media. Social media contains multimodal information, such as texts, images, user IDs, timestamps, locations, etc. Many studies have presented various feature extraction methods to retrieve the multimodal features and used the retrieved features to predict the popularity of posts. However, they often overlook the phenomenon that the posts made by the same user tend to have similar popularity. In this paper, we propose the MultiModal Framework, called MMF, our winning solution to the Social Media Prediction (SMP) Challenge 2024. MMF derives the post representations by considering the interaction relationships and inter-relationships among the extracted multimodal features. Also, it introduces the pseudo labels to consider the phenomenon that the posts made by the same user tend to have similar popularity and learn the popularity distributions of users in the test dataset. Therefore, MMF can simultaneously learn the relationships between post representations and true labels from the data of the training dataset, and users' popularity distributions from the data of the test dataset. The extensive experiments on the Social Media Prediction Dataset show that our proposed framework outperforms the compared models in terms of Spearman's rank correlation and mean absolute error.},
author = {Yu-Shi Lin and Anthony J.T. Lee},
journal = {Proceedings of the 32nd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3664647.3688997},
}

@article{982e7a0d28a0e3da08c0330aa7a45ecb0264b96b,
title = {SMPC: boosting social media popularity prediction with caption},
year = {2023},
url = {https://www.semanticscholar.org/paper/982e7a0d28a0e3da08c0330aa7a45ecb0264b96b},
abstract = {S2 TL;DR: This paper proposes social media popularity prediction with caption (SMPC), a novel architecture that integrates the caption as the global representation into the existing multi-model-feature-based popularity prediction method.},
author = {Anjin Liu and Xiaowen Wang and Ning Xu and Jing Liu and Yuting Su and Quan Zhang and Shenyuan Zhang and Yejun Tang and Junbo Guo and Guoqing Jin and Xuanya Li},
journal = {Multimedia Systems},
volume = {29},
pages = {577-586},
doi = {10.1007/s00530-022-01030-5},
}

@article{3af33f7e230c787aced30bf08099a7aff2b240f7,
title = {Cross-Modal Prototype Augmentation and Dual-Grained Prompt Learning for Social Media Popularity Prediction},
year = {2025},
url = {https://www.semanticscholar.org/paper/3af33f7e230c787aced30bf08099a7aff2b240f7},
abstract = {Social Media Popularity Prediction is a complex multimodal task that requires effective integration of images, text, and structured information. However, current approaches suffer from inadequate visual-textual alignment and fail to capture the inherent cross-content correlations and hierarchical patterns in social media data. To overcome these limitations, we establish a multi-class framework , introducing hierarchical prototypes for structural enhancement and contrastive learning for improved vision-text alignment. Furthermore, we propose a feature-enhanced framework integrating dual-grained prompt learning and cross-modal attention mechanisms, achieving precise multimodal representation through fine-grained category modeling. Experimental results demonstrate state-of-the-art performance on benchmark metrics, establishing new reference standards for multimodal social media analysis.},
author = {Ao Zhou and Mingsheng Tu and Luping Wang and Tenghao Sun and Zifeng Cheng and Yafeng Yin and Zhiwei Jiang and Qing Gu},
journal = {Proceedings of the 33rd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3746027.3763784},
arxivid = {2508.16147},
}

@article{f97a31274f83edb369a48e1233bb42b2d921cb05,
title = {SMP Challenge: An Overview and Analysis of Social Media Prediction Challenge},
year = {2023},
url = {https://www.semanticscholar.org/paper/f97a31274f83edb369a48e1233bb42b2d921cb05},
abstract = {Social Media Popularity Prediction (SMPP) is a crucial task that involves automatically predicting future popularity values of online posts, leveraging vast amounts of multimodal data available on social media platforms. Studying and investigating social media popularity becomes central to various online applications and requires novel methods of comprehensive analysis, multimodal comprehension, and accurate prediction. SMP Challenge is an annual research activity that has spurred academic exploration in this area. This paper summarizes the challenging task, data, and research progress. As a critical resource for evaluating and benchmarking predictive models, we have released a large-scale SMPD benchmark encompassing approximately half a million posts authored by around 70K users. The research progress analysis provides an overall analysis of the solutions and trends in recent years. The SMP Challenge website (www.smp-challenge.com) provides the latest information and news.},
author = {Bo Wu and Peiye Liu and Wen-Huang Cheng and Bei Liu and Zhaoyang Zeng and Jia Wang and Qiushi Huang and Jiebo Luo},
journal = {Proceedings of the 31st ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3581783.3613853},
arxivid = {2405.10497},
}

@article{201d35888b98d29ba86c5e94c7be8b45b25ea23a,
title = {SMP Challenge: An Overview of Social Media Prediction Challenge 2019},
year = {2019},
url = {https://www.semanticscholar.org/paper/201d35888b98d29ba86c5e94c7be8b45b25ea23a},
abstract = {"SMP Challenge" aims to discover novel prediction tasks for numerous data on social multimedia and seek excellent research teams. Making predictions via social multimedia data (e.g. photos, videos or news) is not only helps us to make better strategic decisions for the future, but also explores advanced predictive learning and analytic methods on various problems and scenarios, such as multimedia recommendation, advertising system, fashion analysis etc. In the SMP Challenge at ACM Multimedia 2019, we introduce a novel prediction task Temporal Popularity Prediction, which focuses on predicting future interaction or attractiveness (in terms of clicks, views or likes etc.) of new online posts in social media feeds before uploading. We also collected and released a large-scale SMPD benchmark with over 480K posts from 69K users. In this paper, we define the challenge problem, give an overview of the dataset, present statistics of rich information for data and annotation and design the accuracy and correlation evaluation metrics for temporal popularity prediction to the challenge.},
author = {Bo Wu and Wen-Huang Cheng and Peiye Liu and Zhaoyang Zeng and Jiebo Luo},
journal = {Proceedings of the 27th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3343031.3356084},
arxivid = {1910.01795},
}

@article{c894f321dcda35c64d2ccff42f42f7a201e32453,
title = {FAME: Fusion-Aware Multi-modal Ensemble for Social Media Popularity Prediction},
year = {2025},
url = {https://www.semanticscholar.org/paper/c894f321dcda35c64d2ccff42f42f7a201e32453},
abstract = {As social media becomes a dominant platform for sharing content, predicting the popularity of user posts has become increasingly important for applications such as content recommendation, trend forecasting, and user engagement. However, this task is challenging due to the diverse and multimodal nature of social media posts, which often include unstructured text, images, and structured metadata. To address this challenge, we propose Fusion-Aware Multi-modal Ensemble (FAME), a framework effectively captures and integrates diverse information sources within social media content. Unlike prior approaches that rely on a single model to process all modalities, FAME leverages four specialized predictors. Three of them-CatBoost, LightGBM, and AutoGluon-are tree-based models that excel at handling structured metadata and its interactions with unstructured features. The fourth is a denoising autoencoder (DAE), which learns robust joint representations from unstructured text and image data. These models are combined through a weighted ensemble strategy, allowing FAME to leverage the complementary strengths of different architectures. Experiments on the Social Media Prediction Dataset demonstrate that FAME significantly outperforms existing baselines, achieving state-of-the-art results and validating its effectiveness in modeling the complex, multimodal nature of social media content.},
author = {Zhuang Yan and Wei Bai and Yanru Zhang and Minhao Liu and Jiawen Deng and Fu-ji Ren},
journal = {Proceedings of the 33rd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3746027.3763759},
}

@article{ff90d6a2b85031cbc4897a4518add965a265baf7,
title = {Anchoring Trends: Mitigating Social Media Popularity Prediction Drift via Feature Clustering and Expansion},
year = {2025},
url = {https://www.semanticscholar.org/paper/ff90d6a2b85031cbc4897a4518add965a265baf7},
abstract = {Predicting online video popularity faces a critical challenge: prediction drift, where models trained on historical data rapidly degrade due to evolving viral trends and user behaviors. To address this temporal distribution shift, we propose an Anchored Multi-modal Clustering and Feature Generation (AMCFG) framework that discovers temporally-invariant patterns across data distributions. Our approach employs multi-modal clustering to reveal content structure, then leverages Large Language Models (LLMs) to generate semantic Anchor Features-high-level concepts such as audience demographics, content themes, and engagement patterns-that transcend superficial trend variations. These semantic anchors, combined with cluster-derived statistical features, enable prediction based on stable principles rather than ephemeral signals. Experiments demonstrate that AMCFG significantly enhances both predictive accuracy and temporal robustness, achieving superior performance on out-of-distribution data and providing a viable solution for real-world video popularity prediction.},
author = {Chia-Ming Lee and Bo-Cheng Qiu and Cheng-Jun Kang and Yi-Hsuan Wu and Jun-Lin Chen and Yu-Fan Lin and Yi-Shiuan Chou and Chih-Chung Hsu},
journal = {Proceedings of the 33rd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3746027.3763763},
arxivid = {2507.19863},
}

@article{2420be8f7b598d81f84613aeadda5bf9d0ad7951,
title = {Revisiting Vision-Language Features Adaptation and Inconsistency for Social Media Popularity Prediction},
year = {2024},
url = {https://www.semanticscholar.org/paper/2420be8f7b598d81f84613aeadda5bf9d0ad7951},
abstract = {Social media popularity (SMP) prediction is a complex task involving multi-modal data integration. While pre-trained vision-language models (VLMs) like CLIP have been widely adopted for this task, their effectiveness in capturing the unique characteristics of social media content remains unexplored. This paper critically examines the applicability of CLIP-based features in SMP prediction, focusing on the overlooked phenomenon of semantic inconsistency between images and text in social media posts. Through extensive analysis, we demonstrate that this inconsistency increases with post popularity, challenging the conventional use of VLM features. We provide a comprehensive investigation of semantic inconsistency across different popularity intervals and analyze the impact of VLM feature adaptation on SMP tasks. Our experiments reveal that incorporating inconsistency measures and adapted text features significantly improves model performance, achieving an SRC of 0.729 and an MAE of 1.227. These findings not only enhance SMP prediction accuracy but also provide crucial insights for developing more targeted approaches in social media analysis.},
author = {Chih-Chung Hsu and Chia-Ming Lee and Yu-Fan Lin and Yi-Shiuan Chou and Chih-Yu Jian and Chin-Han Tsai},
journal = {Proceedings of the 32nd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3664647.3689000},
arxivid = {2407.00556},
}

@article{a27d54339e7d8f3cff9ca5b28d2821d9eda25c4e,
title = {A Comprehensive Study of Spatiotemporal Feature Learning for Social Medial Popularity Prediction},
year = {2022},
url = {https://www.semanticscholar.org/paper/a27d54339e7d8f3cff9ca5b28d2821d9eda25c4e},
abstract = {For accurately predicting the popularity of social media, the multi-modal approach was usually adopted to have promising performance. However, the popularity is highly correlated to its identity (i.e., user ID). Inappropriate data splitting could result in lower generalizability in real-world applications. Specifically, we observed that the training and testing datasets are partitioned on a specific timestamp, whereas some users were registered after the timestamp, implying that the partial identities could be missing in the testing phase. It turns the social media prediction (SMP) tasks temporally irrelevant, making the temporal-related feature useless due to missing identities. Therefore, we form the SMP task as an identity-preserving time-series task to observe the popularity scores for the specific identity. In addition, more valuable and essential features could be explored. In this paper, by reformulating the SMP tasks and integrating the multi-modal feature aggregation to the base learner for better performance, how identity-preserving is an essential property for SMP tasks is discussed. We firstly explore the impact of the temporal features with/without identity information in the conventional SMP tasks. Moreover, we reformulate the SMP task in the time-series data-splitting and evaluate the temporal features' importance. Comprehensive experiments are conducted to deliver the suggestions for the SMP tasks and offer the corresponding solutions for effectively predicting the popularity scores.},
author = {Chih-Chung Hsu and Pi-Ju Tsai and Tingchun Yeh and Xiu-Yu Hou},
journal = {Proceedings of the 30th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3503161.3551593},
}

@article{a5bd9be882287416133dcf4ae1fc20aeb92bfe92,
title = {Model Can Be Subtle: Two Important Mechanisms for Social Media Popularity Prediction},
year = {2024},
url = {https://www.semanticscholar.org/paper/a5bd9be882287416133dcf4ae1fc20aeb92bfe92},
abstract = {Social media popularity prediction is an important channel to explore content sharing and communication on social networks. It aims to capture informative cues by analyzing multi-type data (such as user profile, image, and text) to decide the popularity of a specified post. In this article, we divide social network users into two categories (i.e., active and inactive users) and find a dilemma in existing models: If an active user publishes the low-popularity post, the model will habitually predict the high score. On the contrary, if an inactive user provides the high-popularity post, the model still gives the low score incorrectly. Therefore, how to make the model more subtle to users is important. Comparing to existing methods that directly leverage multi-modal features for regression training, this article stresses more on two novel mechanisms. The first method aims to prevent the over-fitting on user IDs. We propose the attribute-sensitive interactive mechanism (M1) by incorporating explicit user-attribute and post-attribute interaction. It can analyze which type of features a user cares the most and weaken the model’s dependence on user IDs. The second method aims to strengthen the influence of post content. We propose the knowledge embedding mechanism (M2) to revise the popularity scores in existing models by fusing the statistical frequency over multi-type data. Note that both mechanisms are model-agnostic, which can be applicable in any popularity prediction model. Extensive experiments conducted on the Social Media Prediction Dataset further validate the effectiveness.},
author = {Ning Xu and Xiaowen Wang and Jing Liu and Lanjun Wang and Xuanya Li and Mengxiao Zhu and Yongdong Zhang and Anan Liu},
journal = {ACM Transactions on Multimedia Computing, Communications and Applications},
volume = {21},
pages = {1 - 20},
doi = {10.1145/3705319},
}

@article{6fe958b9291e961c9392722f1b6bfc92691bcd7a,
title = {An Efficient Multi-View Multimodal Data Processing Framework for Social Media Popularity Prediction},
year = {2022},
url = {https://www.semanticscholar.org/paper/6fe958b9291e961c9392722f1b6bfc92691bcd7a},
abstract = {Popularity of social media is an important symbol of its communication power. Predictions of social media popularity have tremendous business and social value. In this paper, we propose an efficient multimodal data processing framework, which can comprehensively extract the multi-view features from multimodal social media data and achieve accurate popularity prediction. We utilize Transformer and sliding window average to extract time series features of posts, utilize CatBoost to calculate the importance of different features, and integrate important features extracted from multiple views for accurate prediction of social media popularity. We evaluate our proposed approach with the Social Media Prediction Dataset. Experimental results show that our approach achieves excellent performance in the social media popularity prediction task.},
author = {Yunpeng Tan and Fang Liu and Bowei Li and Zheng Zhang and Bo Zhang},
journal = {Proceedings of the 30th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3503161.3551607},
}

@article{c9333f44d2409e7f4166201e40fcd5ca84c7cd54,
title = {Deeply Exploit Visual and Language Information for Social Media Popularity Prediction},
year = {2022},
url = {https://www.semanticscholar.org/paper/c9333f44d2409e7f4166201e40fcd5ca84c7cd54},
abstract = {Social media popularity prediction task is to predict future attractiveness of new posts, which could be applied for online advertising, social recommendation, and demand prediction. Existing methods have explored multiple feature types to model the popularity prediction, including user profile, tag, space-time, category, and others. However, images and texts of social media posts, as important and primary information, are usually used by simple or insufficient processing. In this paper, we propose a method to deeply exploit visual and language information to explore the attractiveness of posts. Specifically, images are parsed from multiple perspectives including multi-modal semantic representation, perceptual image quality, and scene analysis. Different word-level and sentence-level semantic embedding are extracted from all available language texts including title, tags, concept and category. It makes social media popularity modeling more reliable with the powerful visual and language representation. Experimental results demonstrate the effectiveness of exploiting visual and language information by the proposed method, and we achieve new state-of-the-art results on the SMP Challenge at ACM Multimedia 2022.},
author = {Jianmin Wu and Liming Zhao and Dangwei Li and Chen-Wei Xie and Siyang Sun and Yun Zheng},
journal = {Proceedings of the 30th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3503161.3551576},
}

@article{9e9bbe55310132f94596c715902c897511769ac9,
title = {Title-and-Tag Contrastive Vision-and-Language Transformer for Social Media Popularity Prediction},
year = {2022},
url = {https://www.semanticscholar.org/paper/9e9bbe55310132f94596c715902c897511769ac9},
abstract = {Social media is an indispensable part of modern life, and social media popularity prediction (SMPP) plays a vital role in practice. In current work, the inconsistency of words in labels and titles, user feature transformation, etc have not been well noticed. In this paper, we propose a novel approach named Title-and-Tag Contrastive Vision-and-Language Transformer (TTC-VLT), combining two pre-trained vision and language transformers and other two dense feature parts for this prediction task. On one hand, in order to learn the differences between titles and tags, we design title-tag contrastive learning for title-visual and tag-visual, which separately extracts multimodal information from two types of text. On the other hand, user identification features are transformed to embedding vectors to capture user attribute details. From the extensive experiments, our approach outperforms the other methods on the social media prediction dataset. Our team achieve the 2nd place on the leader board of the Social Media Prediction Challenge 2022.},
author = {Weilong Chen and Chenghao Huang and Weimin Yuan and Xiaolu Chen and Wenhao Hu and Xinran Zhang and Yanru Zhang},
journal = {Proceedings of the 30th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3503161.3551568},
}

@article{42c08193ecffa1014b4021a8fafa19f6dbf70a2f,
title = {Overview of the Multimedia Grand Challenges 2022},
year = {2022},
url = {https://www.semanticscholar.org/paper/42c08193ecffa1014b4021a8fafa19f6dbf70a2f},
abstract = {The Multimedia Grand Challenge track was first presented as part of ACM Multimedia 2009 and has established itself as a prestigious competition in the multimedia community. The purpose of the Multimedia Grand Challenges is to engage the multimedia research community by establishing well-defined and objectively judged challenge problems intended to exercise the state-of-the-art methods and inspire future research directions. The key criteria for Grand Challenges are that they should be useful, interesting, and their solution should involve a series of research tasks over a long period of time, with pointers towards longer-term research. The 2022 edition of ACM Multimedia hosted 10 Grand Challenges covering all aspects of multimedia computing, from delivery systems to video retrieval, from video generation to audio recognition.},
author = {Miriam Redi and G. Quénot},
journal = {Proceedings of the 30th ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3503161.3552365},
}

@article{a75acd91d8ade0e7d0319a60a9b52a65859bb355,
title = {Tri-Modal Transformers With Mixture-of-Modality-Experts for Social Media Prediction},
year = {2025},
url = {https://www.semanticscholar.org/paper/a75acd91d8ade0e7d0319a60a9b52a65859bb355},
abstract = {With billions of users worldwide, accurately predicting social media popularity is crucial for assessing user behavior, forecasting trends, and enhancing social interactions and business strategies. However, this task presents significant challenges. Firstly, the extraction of valuable insights is complicated by the presence of tri-modal data (visual, text, structured) and pervasive noise. Secondly, the applicability of knowledge acquired during the pre-training phase is often limited due to discrepancies with downstream prediction tasks during the fine-tuning phase. Existing methods for Social Media Popularity Prediction (SMPP), including traditional models and Visual-and-language Models (VLMs), struggle to overcome these challenges, thereby failing to achieve satisfactory accuracy. To tackle these challenges, we propose a novel approach named Tri-Modal Transformers with Mixture-of-Modality-Experts (TTME) for SMPP. TTME integrates Artificial Intelligence Generated Content to mitigate data noise and incorporate a mix of Modality Experts in pre-training phases to effectively utilize tri-modal data. Moreover, to address training disparity, we explore strategies for downstream task adaptation including the integration of diverse pre-training experts and the implementation of DistillSoftmax. Through empirical evaluation, we demonstrate that the TTME significantly improves the accuracy of social media popularity predictions, effectively utilizes tri-modal data with noise, and enhances transferring knowledge from pre-training to downstream tasks.},
author = {Weilong Chen and Wenhao Hu and Xiaolu Chen and Weimin Yuan and Yan Wang and Yanru Zhang and Zhu Han},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
volume = {35},
pages = {1897-1909},
doi = {10.1109/TCSVT.2024.3474101},
}

@article{d7f617c145a4946d17c802ee437259351a9b98e3,
title = {SMP Challenge Summary: Social Media Prediction Challenge},
year = {2024},
url = {https://www.semanticscholar.org/paper/d7f617c145a4946d17c802ee437259351a9b98e3},
abstract = {SMP Challenge is an annual challenge that seeks top research teams to develop innovative forecasting methods that can enhance social and business applications. We define and introduce the Social Media Popularity Prediction (SMPP) task that predicting the future popularity of a post made by a specific user at a given time on social media. This task is pivotal in various applications and scenarios, such as online advertising, social recommendations, post ranking, and demand forecasting, etc. To motivate diverse perspectives of social media prediction researches, we built a large-scale benchmark Social Media Prediction Dataset (SMPD) that includes approximately 500K posts, along with associated 756 tags, visual-language data, and spatial-temporal information, and sourced from around 70K users and their profiles. With participation and contribution from top teams worldwide, the challenge has seen continuous performance improvements in recent years, driven by technological advancements. For the latest information, leaderboard or online evaluation, please visit the SMP Challenge Homepage: www.smp-challenge.com.},
author = {Bo Wu and Peiye Liu and Qiushi Huang and Zhaoyang Zeng and Jia Wang and Bei Liu and Jiebo Luo and Wen-Huang Cheng},
journal = {Proceedings of the 32nd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3664647.3688996},
}

@article{a08bf6e7fbfd8743cc2f54cb42916ada3841b07c,
title = {Contrastive Learning for Implicit Social Factors in Social Media Popularity Prediction},
year = {2024},
url = {https://www.semanticscholar.org/paper/a08bf6e7fbfd8743cc2f54cb42916ada3841b07c},
abstract = {On social media sharing platforms, some posts are inherently destined for popularity. Therefore, understanding the reasons behind this phenomenon and predicting popularity before post publication holds significant practical value. The previous work predominantly focuses on enhancing post content extraction for better prediction results. However, certain factors introduced by social platforms also impact post popularity, which has not been extensively studied. For instance, users are more likely to engage with posts from individuals they follow, potentially influencing the popularity of these posts. We term these factors, unrelated to the explicit attractiveness of content, as implicit social factors. Through the analysis of users' post browsing behavior (also validated in public datasets), we propose three implicit social factors related to popularity, including content relevance, user influence similarity, and user identity. To model the proposed social factors, we introduce three supervised contrastive learning tasks. For different task objectives and data types, we assign them to different encoders and control their gradient flows to achieve joint optimization. We also design corresponding sampling and augmentation algorithms to improve the effectiveness of contrastive learning. Extensive experiments on the Social Media Popularity Dataset validate the superiority of our proposed method and also confirm the important role of implicit social factors in popularity prediction. We open source the code at https://github.com/Daisy-zzz/PPCL.git.},
author = {Zhizhen Zhang and Ruihong Qiu and Xiao-Zhu Xie},
journal = {ArXiv},
volume = {abs/2410.09345},
pages = {null},
doi = {10.48550/arXiv.2410.09345},
arxivid = {2410.09345},
}

@article{5994b3aaa45e6907ad92489f66686ff86d30ed6a,
title = {Improving Social Media Popularity Prediction with Multiple Post Dependencies},
year = {2023},
url = {https://www.semanticscholar.org/paper/5994b3aaa45e6907ad92489f66686ff86d30ed6a},
abstract = {Social Media Popularity Prediction has drawn a lot of attention because of its profound impact on many different applications, such as recommendation systems and multimedia advertising. Despite recent efforts to leverage the content of social media posts to improve prediction accuracy, many existing models fail to fully exploit the multiple dependencies between posts, which are important to comprehensively extract content information from posts. To tackle this problem, we propose a novel prediction framework named Dependency-aware Sequence Network (DSN) that exploits both intra- and inter-post dependencies. For intra-post dependency, DSN adopts a multimodal feature extractor with an efficient fine-tuning strategy to obtain task-specific representations from images and textual information of posts. For inter-post dependency, DSN uses a hierarchical information propagation method to learn category representations that could better describe the difference between posts. DSN also exploits recurrent networks with a series of gating layers for more flexible local temporal processing abilities and multi-head attention for long-term dependencies. The experimental results on the Social Media Popularity Dataset demonstrate the superiority of our method compared to existing state-of-the-art models.},
author = {Zhizhen Zhang and Xiao-Zhu Xie and Meng Yang and Ye Tian and Yong Jiang and Yong Cui},
journal = {ArXiv},
volume = {abs/2307.15413},
pages = {null},
doi = {10.48550/arXiv.2307.15413},
arxivid = {2307.15413},
}

@article{ab2480226c1cf93271ad8e650adaef07d968791b,
title = {Feature Disentangling Dual-stream Network for User Bias Alleviation in Social Media Prediction},
year = {2025},
url = {https://www.semanticscholar.org/paper/ab2480226c1cf93271ad8e650adaef07d968791b},
abstract = {Social media popularity prediction is increasingly crucial for optimizing user engagement and guiding content recommendation systems. However, existing methods suffer from an excessive reliance on user information, which disproportionately influences predictions and leads to the neglect of content diversity. This oversight results in user bias, which adversely impacts the accuracy of predictions. In this paper, an approach named Feature Disentangling Dual-Stream Network (FDDN) is introduced to address this gap. In FDDN, we introduce the Multimodal Extraction Module to extract content features from different modalities. Additionally, the User Popularity Extraction Module helps to analyze the impact of user features on popularity. The Disentangled Adaptation Module distinguishes the impact of user features from content features, thus alleviating user bias and ensuring a more comprehensive prediction. Extensive experiments on a large public dataset demonstrate the robustness and effectiveness of our approach, indicating superior performance compared to existing methods.},
author = {Wenhao Hu and Weilong Chen and Weimin Yuan and Xiaolu Chen and Han Yang and Yanru Zhang and Zhu Han},
journal = {ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
volume = {null},
pages = {1-5},
doi = {10.1109/ICASSP49660.2025.10890121},
}

@article{f0dab5380152b4aeb62b1e0c5687b902e179699f,
title = {Social Media Popularity Prediction Based on Multi-Modal Self-Attention Mechanisms},
year = {2022},
url = {https://www.semanticscholar.org/paper/f0dab5380152b4aeb62b1e0c5687b902e179699f},
abstract = {Popularity prediction using social media is an important task because of its wide range of real-world applications such as advertisements, recommendation systems, and trend analysis. However, this task is challenging because social media is affected by multiple factors that cannot be easily modeled (e.g. quality of content, relevance to viewers, real-life events). Usually, other methods adopt the greedy approach to include as many modalities and factors as possible into their model but treat these features equally. To solve this phenomenon, our proposed method leverages the self-attention mechanism to effectively and automatically fuse different features to achieve better performance for the popularity prediction of a post, where the features used in our model can be mainly categorized into two modalities, semantic (text) and numeric features. With extensive experiments and ablation studies on the training and testing data of the challenging ACM Multimedia SMPD 2020 Challenge dataset, the evaluation results demonstrate the effectiveness of the proposed approach as compared with other methods.},
author = {Hung-Hsiang Lin and Jiun-Da Lin and Jose Jaena Mari Ople and Jun-Cheng Chen and K. Hua},
journal = {IEEE Access},
volume = {10},
pages = {4448-4455},
doi = {10.1109/ACCESS.2021.3136552},
}

@article{5f4135304e45b3e7ac1a7aeea547dea2129adfc3,
title = {Sequential Prediction of Social Media Popularity with Deep Temporal Context Networks},
year = {2017},
url = {https://www.semanticscholar.org/paper/5f4135304e45b3e7ac1a7aeea547dea2129adfc3},
abstract = {Prediction of popularity has profound impact for social media, since it offers opportunities to reveal individual preference and public attention from evolutionary social systems. Previous research, although achieves promising results, neglects one distinctive characteristic of social data, i.e., sequentiality. For example, the popularity of online content is generated over time with sequential post streams of social media. To investigate the sequential prediction of popularity, we propose a novel prediction framework called Deep Temporal Context Networks (DTCN) by incorporating both temporal context and temporal attention into account. Our DTCN contains three main components, from embedding, learning to predicting. With a joint embedding network, we obtain a unified deep representation of multi-modal user-post data in a common embedding space. Then, based on the embedded data sequence over time, temporal context learning attempts to recurrently learn two adaptive temporal contexts for sequential popularity. Finally, a novel temporal attention is designed to predict new popularity (the popularity of a new user-post pair) with temporal coherence across multiple time-scales. Experiments on our released image dataset with about 600K Flickr photos demonstrate that DTCN outperforms state-of-the-art deep prediction algorithms, with an average of 21.51% relative performance improvement in the popularity prediction (Spearman Ranking Correlation).},
author = {Bo Wu and Wen-Huang Cheng and Yongdong Zhang and Qiushi Huang and Jintao Li and Tao Mei},
journal = {ArXiv},
volume = {abs/1712.04443},
pages = {null},
doi = {10.24963/ijcai.2017/427},
arxivid = {1712.04443},
}

@article{affd4c5ab2f1fcc81e52ef1f4980db86949bc80e,
title = {Modality-Aligned Hierarchical Attention Network for Multi-Modal Popularity Prediction on Social Media},
year = {2025},
url = {https://www.semanticscholar.org/paper/affd4c5ab2f1fcc81e52ef1f4980db86949bc80e},
abstract = {Social media popularity prediction is essential for content optimization and platform management. Existing approaches often struggle to capture the intricate semantic relationships among heterogeneous content modalities. To solve this problem, we propose a hierarchical attention fusion framework with cross-modal semantic alignment, which integrates text, visual, and user behavior features for enhanced popularity prediction. This design enables the model to adaptively emphasize the most informative features across modalities. We systematically evaluate various regression models and their ensemble strategies on the SMPD dataset, which contains 486,000 social media posts. Experimental results demonstrate that our hierarchical attention fusion consistently outperforms existing fusion methods. These findings highlight the effectiveness of cross-modal semantic alignment and provide valuable insights for advancing multi-modal social media popularity prediction.},
author = {Wenzheng Hou and Weixin Li},
journal = {Proceedings of the 33rd ACM International Conference on Multimedia},
volume = {null},
pages = {null},
doi = {10.1145/3746027.3763760},
}
